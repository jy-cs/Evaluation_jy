{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# COMP-8730_Project Evaluation\n",
        "> ## Student Information\n",
        "> * Name: Jiajie Yang"
      ],
      "metadata": {
        "id": "wwDWYCzl_lFE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlmI0AcM9ZAG"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForQuestionAnswering, AdamW\n",
        "import transformers\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import random\n",
        "\n",
        "#import pandas as pd"
      ],
      "metadata": {
        "id": "1A2caWgZ-LrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ## Sampling\n",
        ">> We pseudo randomly select 500 samples from the JSON file"
      ],
      "metadata": {
        "id": "KTwDYNMjqJRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "df_train = pd.read_json('train_data.json')\n",
        "df_train_subset = df_train.sample(n=1, random_state=42)\n",
        "\n",
        "# Save the subset to a new JSON file\n",
        "df_train_subset.to_json('train_data_subset_500.json')\n",
        "###\n"
      ],
      "metadata": {
        "id": "9tFRllWz46Ny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# /content/BioASQ-train-list-7b-full-annotated.json\n",
        "\n",
        "# set path\n",
        "input_file = '/content/BioASQ-train-list-7b-full-annotated.json'\n",
        "\n",
        "num_s = 500\n",
        "\n",
        "# load data\n",
        "with open(input_file, 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# choose subset\n",
        "sampled_data = random.sample(data['data'][0]['paragraphs'], num_s)\n",
        "\n",
        "# create file\n",
        "output_data = {}\n",
        "output_data['version'] = data['version']\n",
        "output_data['data'] = []\n",
        "for paragraph in sampled_data:\n",
        "    new_paragraph = {}\n",
        "    new_paragraph['context'] = paragraph['context']\n",
        "    new_paragraph['qas'] = []\n",
        "    for qa in paragraph['qas']:\n",
        "        new_qa = {}\n",
        "        new_qa['id'] = qa['id']\n",
        "        new_qa['question'] = qa['question']\n",
        "        new_qa['answers'] = qa['answers']\n",
        "        new_paragraph['qas'].append(new_qa)\n",
        "    output_data['data'].append({'paragraphs': [new_paragraph]})\n",
        "\n",
        "# output file\n",
        "output_file = 'BioASQ-train-list-7b-sampled.json'\n",
        "with open(output_file, 'w') as f:\n",
        "    json.dump(output_data, f, indent=4)\n"
      ],
      "metadata": {
        "id": "pSzXO5cp4Fuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "df_train = pd.read_json(path)\n",
        "df_test = pd.read_json('test_data.json')\n",
        "# tokenization\n",
        "tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "train_encodings = tokenizer(list(df_train['text']), truncation=True, padding=True)\n",
        "test_encodings = tokenizer(list(df_test['text']), truncation=True, padding=True)\n",
        "\n",
        "# create BERT\n",
        "train_inputs = np.array(train_encodings['input_ids'])\n",
        "train_masks = np.array(train_encodings['attention_mask'])\n",
        "train_labels = np.array(df_train['labels'])\n",
        "test_inputs = np.array(test_encodings['input_ids'])\n",
        "test_masks = np.array(test_encodings['attention_mask'])\n",
        "test_labels = np.array(df_test['labels'])\n",
        "###\n"
      ],
      "metadata": {
        "id": "IOhD7dAV1N2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ## Produing results\n",
        ">> We apply the model on the sampled JSON file"
      ],
      "metadata": {
        "id": "hokVcZx46QaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForQuestionAnswering.from_pretrained('bert-base-uncased').to(device)\n",
        "\n",
        "# create training dataset\n",
        "training_data = []\n",
        "for paragraph in sampled_data:\n",
        "    context = paragraph['context']\n",
        "    for qa in paragraph['qas']:\n",
        "        question = qa['question']\n",
        "        answer_start = qa['answers'][0]['answer_start']\n",
        "        answer_text = qa['answers'][0]['text']\n",
        "        training_data.append({'context': context, 'question': question, 'answer_text': answer_text, 'answer_start': answer_start})\n",
        "\n",
        "# tokenization\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "token_type_ids = []\n",
        "start_positions = []\n",
        "end_positions = []\n",
        "for example in training_data:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "        example['question'],\n",
        "        example['context'],\n",
        "        add_special_tokens=True,\n",
        "        max_length=512,\n",
        "        pad_to_max_length=True,\n",
        "        return_tensors='pt',\n",
        "        return_attention_mask=True,\n",
        "        return_token_type_ids=True)\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "    token_type_ids.append(encoded_dict['token_type_ids'])\n",
        "    start_positions.append(torch.tensor([example['answer_start']]))\n",
        "    end_positions.append(torch.tensor([example['answer_start'] + len(example['answer_text'])]))\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "token_type_ids = torch.cat(token_type_ids, dim=0)\n",
        "start_positions = torch.cat(start_positions, dim=0)\n",
        "end_positions = torch.cat(end_positions, dim=0)\n",
        "\n",
        "# create optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "num_epochs = 3\n",
        "\n",
        "# fine-tuning\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    for i in range(len(input_ids)):\n",
        "        input_id = input_ids[i].unsqueeze(0).to(device)\n",
        "        attention_mask = attention_masks[i].unsqueeze(0).to(device)\n",
        "        token_type_id = token_type_ids[i].unsqueeze(0).to(device)\n",
        "        start_pos = start_positions[i].unsqueeze(0).to(device)\n",
        "        end_pos = end_positions[i].unsqueeze(0).to(device)\n",
        "        outputs = model(input_ids=input_id, attention_mask=attention_mask, token_type_ids=token_type_id, start_positions=start_pos, end_positions=end_pos)\n",
        "        loss = outputs.loss\n",
        "        losses.append(loss.item())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "    avg_loss = sum(losses) / len(losses)\n",
        "    print(avg_loss)\n",
        "\n",
        "# save\n",
        "model.save_pretrained('model_1')\n"
      ],
      "metadata": {
        "id": "ASJiQ7fP6c9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ## Testing\n",
        ">> We apply the fine-tuned model on a test"
      ],
      "metadata": {
        "id": "PjPuoB4o7QRO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"List symptoms of the IFAP syndrome.\"\n",
        "context = \"Ichthyosis follicularis with atrichia and photophobia (IFAP) syndrome in two unrelated female patients. The IFAP syndrome is characterized by the congenital onset of ichthyosis follicularis, absence of hair, and photophobia. A limited number of patients with the disorder have been described, and X-linked recessive inheritance has been proposed. Two unrelated female patients with a complete IFAP syndrome are reported. Both patients show a diffuse distribution of the disorder without linear arrangement. Because the suggested X-linked recessive pattern of inheritance is unlikely in these patients, a different way of transmission or, alternatively, genetic heterogeneity of the disorder has to be considered.\"\n",
        "input_dict = tokenizer.encode_plus(question, context, return_tensors='pt')\n",
        "input_ids = input_dict['input_ids'].to(device)\n",
        "token_type_ids = input_dict['token_type_ids'].to(device)\n",
        "attention_mask = input_dict['attention_mask'].to(device)\n",
        "outputs = model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "start_scores = outputs.start_logits\n",
        "end_scores = outputs.end_logits\n",
        "start_index = torch.argmax(start_scores)\n",
        "end_index = torch.argmax(end_scores)\n",
        "answer_tokens = input_ids[0][start_index:end_index+1]\n",
        "answer_tokens = tokenizer.convert_ids_to_tokens(answer_tokens)\n",
        "answer = tokenizer.convert_tokens_to_string(answer_tokens)\n",
        "\n",
        "print('Question:', question)\n",
        "print('Answer:', answer)\n"
      ],
      "metadata": {
        "id": "yTVRGDEk7bo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ## Evaluation\n",
        ">> We will first evaluate our model above and then compare with other simpler models and naive models"
      ],
      "metadata": {
        "id": "Zl7XGHEY9cFu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
        "from sklearn.metrics import accuracy_score, f1_score, average_precision_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# use model-1\n",
        "model = AutoModelForQuestionAnswering.from_pretrained('/content/model_1')\n",
        "tokenizer = AutoTokenizer.from_pretrained('/content/model_1')\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "# load data\n",
        "with open('/content/BioASQ-train-list-7b-full-annotated-sampled.json', 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# evaluation\n",
        "def evaluate_model_1(data):\n",
        "    true_answers = []\n",
        "    predicted_answers = []\n",
        "    for query in data['queries']:\n",
        "        question = query['question']\n",
        "        for document in query['documents']:\n",
        "            context = document['title'] + ' ' + document['abstractText']\n",
        "            true_answer = document['exactAnswer']\n",
        "            input_dict = tokenizer.encode_plus(question, context, return_tensors='pt')\n",
        "            input_ids = input_dict['input_ids'].to(device)\n",
        "            token_type_ids = input_dict['token_type_ids'].to(device)\n",
        "            attention_mask = input_dict['attention_mask'].to(device)\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "            start_scores = outputs.start_logits\n",
        "            end_scores = outputs.end_logits\n",
        "            start_index = torch.argmax(start_scores)\n",
        "            end_index = torch.argmax(end_scores)\n",
        "            answer_tokens = input_ids[0][start_index:end_index+1]\n",
        "            answer_tokens = tokenizer.convert_ids_to_tokens(answer_tokens)\n",
        "            predicted_answer = tokenizer.convert_tokens_to_string(answer_tokens)\n",
        "            true_answers.append(true_answer)\n",
        "            predicted_answers.append(predicted_answer)\n",
        "    accuracy = accuracy_score(true_answers, predicted_answers)\n",
        "    f1 = f1_score(true_answers, predicted_answers, average='weighted')\n",
        "    map_score = average_precision_score(true_answers, predicted_answers)\n",
        "    return accuracy, f1, map_score\n",
        "\n",
        "accuracy, f1, map_score = evaluate_model_1(data)\n",
        "print('Accuracy:', accuracy)\n",
        "print('F1-score:', f1)\n",
        "print('MAP:',map_score)\n",
        "\n",
        "\n",
        "# standard scores\n",
        "fig, accf_s = plt.subplots(nrows=2, ncols=2, figsize=(12, 8))\n",
        "accf_s = accf_s.ravel()\n",
        "\n",
        "# loss\n",
        "accf_s[0].plot(range(1, len(avg_loss_history)+1), avg_loss_history)\n",
        "accf_s[0].set_xlabel('Epoch')\n",
        "accf_s[0].set_ylabel('Training Loss')\n",
        "accf_s[0].set_title('Training Loss')\n",
        "\n",
        "# accuracy\n",
        "accf_s[1].plot(range(1, len(accuracy_history)+1), accuracy_history)\n",
        "accf_s[1].set_xlabel('Epoch')\n",
        "accf_s[1].set_ylabel('Accuracy')\n",
        "accf_s[1].set_title('Accuracy')\n",
        "\n",
        "# F1\n",
        "accf_s[2].plot(range(1, len(f1_score_history)+1), f1_score_history)\n",
        "accf_s[2].set_xlabel('Epoch')\n",
        "accf_s[2].set_ylabel('F1-score')\n",
        "accf_s[2].set_title('F1-score')\n",
        "\n",
        "# MAP\n",
        "accf_s[3].plot(range(1, len(map_score_history)+1), map_score_history)\n",
        "accf_s[3].set_xlabel('Epoch')\n",
        "accf_s[3].set_ylabel('MAP score')\n",
        "accf_s[3].set_title('MAP score')\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "GswmWoOc9jrj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}